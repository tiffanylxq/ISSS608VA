---
title: "Take-Home Exercise 4"
description: |

  Putting Visual Analytics into Practical Use

author:
  - name: Lee Xiao Qi 
    url: https://example.com/norajones
    affiliation: School of Computing and Information Systems (SMU)
    affiliation_url: https://example.com/spacelysprokets
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

# 1. The Task

We are required to attempt bullet point 3 of Challenge 2 of [VAST Challenge 2022](https://vast-challenge.github.io/2022/) which is:

**"Participants have given permission to have their daily routines captured. Choose two different participants with different routines and describe their daily patterns, with supporting evidence. Limit your response to 10 images and 500 words."**

We are to use ViSIElse and other appropriate visual analytics methods to reveal the daily routines of two selected participant of the city of Engagement, Ohio USA. 

# 2. The Preparation

### 2.1 About the Data

About 1000 representative residents have volunteered to provide data using the cityâ€™s urban planning app, which records the places they visit, their spending, and their purchases, among other things; in particular, the **Activity Logs** dataset recorded the status of each participant in 5-minute increments over the duration of
the 15-month data collection period.

For this exercise, we have selected **ID 180** & **1000** and only look at 3 different dates **(18 July 2022, 22 July 2022, 23 July 2022)** of the 15 month period to see their daily routine on a Monday, Friday and Saturday.

### 2.2 Importing the relevant packages and data

The following packages within the code chunk below is install and load onto RStudio.

```{r}
packages = c('scales', 'viridis', 
             'lubridate', 'ggthemes', 
             'gridExtra', 'tidyverse', 
             'readxl', 'knitr',
             'data.table', 'ViSiElse','matrixStats')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

The code chuck below imports multiple files (`ParticipantStatusLogs23.csv` & `ParticipantStatusLogs24.csv`) from the **Activity Log** data folder into R by using `list.files()`.

```{r}
logs_fread <- list.files(path = "./data/ActivityLogs/",
                  pattern = "*.csv", 
                  full.names = T) %>% 
  map_df(~fread(.))

```


```{r}
P180a <- logs_fread[grep("180", logs_fread$participantId),]


```
### 2.3 Data Structure 

We want to combine the `currentMode` and `sleepStatus` column to different the different modes that the participants are when they are at home; and also compute total duration (in mins) for each activity.

```{r}
P180b <-
  mutate(P180a, AM_PM =
        (format(P180a$timestamp, "%p")))

P180b <-
  mutate(P180b, Date =
        (as.Date(P180b$timestamp)))

P180b <-
  mutate(P180b, Time=as.numeric(5))

P180b$Activity <- paste(P180b$currentMode, P180b$sleepStatus,P180b$Activity, P180b$AM_PM, sep="_")

```


```{r}
P180_filtered <- P180b[, -c(1:13)]
P180_filtered <-  filter(P180_filtered, Date == "2022-07-18" | Date == "2022-07-22"|Date == "2022-07-23")

```


### 2.4 RDS Format 

Dataframe *P180* and *P1000* are saved and read in RDS format to avoid uploading large files to Git.

```{r,eval=FALSE}
 write_rds(P180_filtered, "data/rds/P180_filtered")

```

We will load back the `P180_filtered.rds` file and work on these file henceforth.

```{r}
P180_filtered <- read_rds("data/rds/P180_filtered")

```


```{r}
P180a <- P180_filtered %>%
  pivot_wider(names_from = Activity, values_from = Time, values_fill = 0, values_fn = sum)
```

```{r}
P180a<- t(apply(P180a[, (2:9)], 1, cumsum))
P180b<-as.data.frame(P180a)
P180c <-  as.integer(P180b[1,1:8])

```



```{r}
visielse(P180b, informer = NULL)
```

```{r}
P180c <- P180b %>%
  arrange(AM_PM) %>% 
  group_by(Date, Activity) %>%
  summarise(Duration = sum(Time),.groups = 'drop')

```

```{r}

P180d <- P180c %>% spread(key = Activity, value = Duration)

```

#### 2.4 Fliter Selected Participants

```{r}
P180 <- logs_fread[grep("180", logs_fread$participantId),]

P1000 <- logs_fread[grep("1000", logs_fread$participantId),]

```


#### 2.3.2 Renaming of Columns and Values

First, we start by renaming the columns and values of in *Employers* and *Checkin* dataset using the function [`rename()`](https://dplyr.tidyverse.org/reference/rename.html), and [`sub()`](https://www.datasciencemadesimple.com/sub-gsub-function-in-r/) for a better format and ease of reading.

Note: A check between both datasets shows that `venueId` in *Checkin* dataset refers to the `employerId`, `pubId` etc. For the purpose of this exercise, we are only interested in the `employerId` (`venueType` = `Workspace`) and other venues type will be removed subsequently.

```{r}
# rename columns
Employers <- Employers %>%
  rename('Employer_ID' = 'employerId', 
         'Location(Pt)' = 'location.x', 
         'Location(Area)' = 'location.y',
         'Building_ID' = 'buildingId', 
         'Building_Type' = 'buildingType', 
         'Max_Occupancy' = 'maxOccupancy', 
         'Units' = 'units', 
         'Job_ID' = 'jobId',
         'Hourly_Rate' = 'hourlyRate',
         'Start_Time' = 'startTime',
         'End_Time' = 'endTime',
         'Days_To_Work' = 'daysToWork',
         'Education_Level' = 'educationRequirement')

Buildings <- Buildings %>%
  rename('Building_Type' = 'buildingType', 
         'Building_ID' = 'buildingId')

Checkin <- Checkin %>%
  rename('Participant_ID' = 'participantId', 
         'Timestamp' = 'timestamp', 
         'Employer_ID' = 'venueId',
         'Venue_Type' = 'venueType')

Jobs <- Jobs %>%
  rename('Education_Level' = 'educationRequirement')


Participants <- Participants %>%
  rename('Participant_ID' = 'participantId', 
         'Household_Size' = 'householdSize', 
         'Have_Kids' = 'haveKids', 
         'Age' = 'age', 
         'Education_Level' = 'educationLevel', 
         'Interest_Group' = 'interestGroup', 
         'Joviality' = 'joviality')

#rename row values
Employers$Education_Level <- sub('HighSchoolOrCollege', 
                                    'High School or College',
                                    Employers$Education_Level)
Jobs$Education_Level <- sub('HighSchoolOrCollege', 
                                    'High School or College',
                                    Jobs$Education_Level)
Participants$Education_Level <- sub('HighSchoolOrCollege', 
                                    'High School or College',
                                    Participants$Education_Level)

```
#### 2.3.3 Compute frequency count of returns by sub-category

We are using *Checkin* to see the changes in employment (i.e. checkin by participants at workplace) over time. We see that the `venueId` column in the dataset are IDs of all possible venues such as work place, restaurants and pubs. 

Given that we are only interested in workplace, we will first co the frequency get the subset of row that reads "workplace" using `grep()`. the this column as `buildingId` and left join with *Employers*.   

Compute frequency count of returns by sub-category
Then, the frequency count of returns by sub-category is computed by using the group_by method found in dplyr.

GROUP_BY METHOD
```{r}
#Extract the date from timestamp
Checkin$Date <- as.Date(Checkin$Timestamp)

#Fliter rows with workplace as value
Workplace_Checkin <- Checkin[grep("Workplace", Checkin$Venue_Type),]

#Compute count frequency of participants by date in each venue
Count_Checkin <- Workplace_Checkin %>%
  group_by(Date, Employer_ID) %>%
  summarise('Num_of_Employees'= n_distinct(Participant_ID))  

```

# 3. Visualizing with Charts

Next, we put up a series of charts to address the question.

### 1) How Big are these Companies?

```{r,echo=FALSE}
library(magrittr)
```

```{r,fig.width=20, fig.height=20}
Employers <- Employers %>% mutate(Duration = End_Time - Start_Time)

Employers <-Employers %>% mutate(across(c(Duration), as.numeric)) 

Employers <- Employers %>% mutate(Weekly_Wages = Duration/ 60 / 60 * Hourly_Rate)
  
```



```{r,fig.width=20, fig.height=20}
Employers$Employer_ID <- as.character(Employers$Employer_ID)
Employers$Building_ID <- as.character(Employers$Building_ID)

ggplot(Employers, aes(Employer_ID, Education_Level, fill = Hourly_Rate)) + 
     geom_tile(color = "white") +
  scale_fill_gradient(low = "yellow", high = "purple") +
      labs(title ="Growth of Employment by States and NIC", x = "Employer_ID", y = "Age Group", fill = "Hourly_Rate")+ 
    theme(axis.text.x = element_text(angle = 0, hjust = 1.0))
 
```


```{r}

Count_Checkin$Employer_ID <- as.character(Count_Checkin$Employer_ID)

```


```{r,fig.width=20, fig.height=20}

p<- ggplot(Count_Checkin, aes(x=Employer_ID, y=Num_of_Employees)) +
  geom_bar(stat="identity") +
  ylim(1,15)+
  coord_polar()+
  transition_time(Date) +
  labs(title = "Date: {frame_time}")

animate(p, duration = 274,height = 800, width =800)
```
 

 
```{r,fig.width=20, fig.height=20}
 Participants$Age_Group <- cut(Participants$Age,
                                  breaks = c(-Inf,21, 31, 41, 51, 61, Inf),
                                  labels = c("<21", "21-30","31-40","41-50","51-60", ">60"),
                                  right = FALSE)
``` 

```{r}
Workplace_Checkin <- Workplace_Checkin %>% left_join(Participants,by="Participant_ID")

Count_Work_AgeGroup <- Workplace_Checkin %>%
  group_by(Date, Employer_ID, Participant_ID) %>%
  summarise('Num_of_Employees'= n_distinct(Participant_ID))  

Count_Work_AgeGroup <- Count_Work_AgeGroup %>% left_join(Participants,by="Participant_ID")



```

```{r}
 Count_Work_AgeGroup <- Workplace_Checkin %>%
  group_by(Date, Employer_ID, Age_Group) %>%
  summarise('Num_of_Employees'= n_distinct(Participant_ID)) 
```


```{r,fig.width=20, fig.height=20}

q<- Count_Work_AgeGroup$Employer_ID <- as.character(Count_Work_AgeGroup$Employer_ID)
ggplot(Count_Work_AgeGroup, aes(Employer_ID, Age_Group,fill = Num_of_Employees)) + 
     geom_tile(color = "white") +
  scale_fill_gradient(low = "green", high = "red") +
      labs(title ="Growth of Employment by States and NIC", x = "Employer_ID", y = "Age Group", fill = "No. of Employees")+ 
    theme(axis.text.x = element_text(angle = 0, hjust = 1.0))+
    transition_time(Date) +
    labs(title = "Date: {frame_time}")

 

```


```{r}

Employer_Employee <- read_csv("data/Employer_Employee.csv")

Employer_Unique_Employee <- Employer_Employee %>%
  group_by(Employer_ID, Week_Num) %>%
  summarise('Num_of_Employees'= n_distinct(Participant_ID))  


```

```{r, fig.width=20, fig.height=20}

Employer_Unique_Employee$Employer_ID <- as.character(Employer_Unique_Employee$Employer_ID)


p<- ggplot(Employer_Unique_Employee, aes(x=Week_Num, y=Num_of_Employees, group=Employer_ID)) +
  geom_line(aes(color=Employer_ID), show.legend = FALSE)+
  ylim(1,15) 

ggplotly(p)


```

```{r,fig.width=14,fig.height=12}

Jobs$Education_Level = factor(Jobs$Education_Level, levels = c('Low', 'High School or College', 'Bachelors','Graduate'))

ggplot(Jobs, aes(x = Education_Level, y = hourlyRate, fill=Education_Level)) + 
  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .25, 
    outlier.shape = NA
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitter(
      seed = 1, width = .1
    )
  ) + 
  coord_cartesian(xlim = c(1.2, NA), clip = "off")+
  ggtitle(label = "Wage Distribution for Different Education Level",
          subtitle = "High Wages For Higher Educated")+
  theme_minimal()+
  theme(plot.title = element_text(size=14, face="bold",hjust = 0.5),
          plot.subtitle = element_text(size=12,hjust = 0.5,color='mediumvioletred'))+
  theme(axis.title.y= element_text(angle=0), axis.ticks.x= element_blank(),
        panel.background= element_blank(), axis.line= element_line(color= 'grey'))
```

```{r,fig.width=20, fig.height=5}

Workplace_Checkin$Employer_ID <- as.character(Workplace_Checkin$Employer_ID)
ggplot(Workplace_Checkin, aes(Employer_ID, Education_Level,fill = Age)) + 
     geom_tile(color = "white") +
  scale_fill_gradient(low = "yellow", high = "purple",na.value="white") +
      labs(title ="Age of Employees by Employer and Education Level", x = "Employer_ID", y = "Education Level", fill = "Age of Employee")+ 
    theme(axis.text.x = element_text(angle = 0, hjust = 1.0))
```
```{r, fig.width=20, fig.height=20}

Employer_Unique_Employee$Employer_ID <- as.character(Employer_Unique_Employee$Employer_ID)
d <- highlight_key(Employer_Unique_Employee)

p<- ggplot(Employer_Unique_Employee, aes(x=Week_Num, y=Num_of_Employees, group=Employer_ID)) +
  geom_line(aes(color=Employer_ID), show.legend = FALSE)+
  ylim(1,15) 

gg <- highlight(ggplotly(p),
                "plotly_selected")
crosstalk::bscols(gg,
                  DT::datatable(d),
                  widths = 5)


```

```{r,fig.width=20, fig.height=5}

Workplace_Checkin$Employer_ID <- as.character(Workplace_Checkin$Employer_ID)

ggplot(Workplace_Checkin, aes(Employer_ID, Education_Level,fill = Age)) + 
     geom_tile(color = "white") +
  scale_fill_gradient(low = "yellow", high = "purple",na.value="white") +
      labs(title ="Age of Employees by Employer and Education Level", x = "Employer_ID", y = "Education Level", fill = "Age of Employee")+ 
    theme(axis.text.x = element_text(angle = 0, hjust = 1.0))
```

